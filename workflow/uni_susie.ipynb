{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Susie whole genome sequencing\n",
    "Ready to use pipeline to estimate univariate association between a molecular phenotype and the genotypes via SuSiE. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Pre-requisites\n",
    "\n",
    "We provide a container image `docker://gaow/twas` that contains all software needed to run the pipeline. If you would like to configure it by yourself, please make sure you install the following software before running this notebook.\n",
    "\n",
    "Bash:\n",
    "- GCTA\n",
    "- PLINK\n",
    "\n",
    "R: \n",
    "- Tidyverse\n",
    "- susieR\n",
    "- modelr\n",
    "- abind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Input and Output\n",
    "## Input\n",
    "\n",
    "- `--genotype_list` An index text file with two columns of chromosome and the corresponding PLINK bed file.\n",
    "- `--molecular-pheno`, The text file containing the table describing the molecular phenotype. It shall have regions(genes) as rows and samples as columnes\n",
    "- `--region_list` The text file with 4 columns specifying the #Chr, P0 (Start position), P1(End position) and names of regions to analyze. The name of the column is not important but the order of the columns. It is also important that the column name of the first column starts with a #. The region_list can can be generated by using another sos pipeline SOS_ROSMAP_gene_exp_processing.ipynb.\n",
    "\n",
    "## Output\n",
    "\n",
    "- `uni_weight.RDS` a RDS file that served as the input for the mixture pipeline.\n",
    "- `susie.RData` a R object containing all the susie output for each of the regions\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Command interface "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run twas_fusion.ipynb [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  twas_fusion\n",
      "  association_test\n",
      "\n",
      "Global Workflow Options:\n",
      "  --molecular-pheno VAL (as path, required)\n",
      "                        Path to the input molecular phenotype data.\n",
      "  --gwas-sumstat VAL (as path, required)\n",
      "                        Path to GWAS summary statistics data (association\n",
      "                        results between SNP and disease in a GWAS)\n",
      "  --genotype-list VAL (as path, required)\n",
      "                        An index text file with two columns of chromosome and\n",
      "                        the corresponding PLINK bed file.\n",
      "  --region-list VAL (as path, required)\n",
      "                        An index text file with 4 columns specifying the chr,\n",
      "                        start, end and names of regions to analyze\n",
      "  --wd . (as path)\n",
      "                        Path to the work directory of the weight computation:\n",
      "                        output weights and cache will be saved to this\n",
      "                        directory.\n",
      "  --weights-path  f'{wd:a}/WEIGHTS'\n",
      "\n",
      "                        Specify the directory to save fitted weights\n",
      "  --weights-list  f'{weights_path}/{molecular_pheno:bn}.weights_list.txt'\n",
      "\n",
      "                        Path to list of weights\n",
      "  --region-name VAL (as int, required)\n",
      "                        Specify the column in the molecular_pheno file that\n",
      "                        contains the name of the region of interest\n",
      "  --data-start VAL (as int, required)\n",
      "                        Specify the column in the molecular_pheno file where the\n",
      "                        actual data start\n",
      "  --window 50000 (as int)\n",
      "                        Specify the scanning window for the up and downstream\n",
      "                        radius to analyze around the region of interest, in\n",
      "                        units of Kb\n",
      "  --model blsmm blup lasso top1 enet (as list)\n",
      "                        Specify what model are used to compute weights. Notice\n",
      "                        that `blsmm` can be very resource consuming.\n",
      "  --container 'gaow/twas'\n",
      "                        Container option for software to run the analysis:\n",
      "                        docker or singularity\n",
      "\n",
      "Sections\n",
      "  twas_fusion_1:\n",
      "  twas_fusion_2:\n",
      "  twas_fusion_3:        Actual weight computation\n",
      "  twas_fusion_4:\n",
      "  twas_fusion_5, association_test: Association test\n",
      "  twas_fusion_6:        Clean up dummy file\n"
     ]
    }
   ],
   "source": [
    "!sos run twas_fusion.ipynb -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Working example\n",
    "The MWE file is availble at :\n",
    "\"https://www.synapse.org/#!Synapse:syn24179064/files/\"\n",
    "\n",
    "The time it take to run this MWE shall be around 2 minutes. Pay extra attention to the gene_start and gene_end position  when using following command on gene_exp file that are not this MWE. Also, when there is too few or too many genes that passed the heritability check, consider increasing or decreasing the --window options. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mERROR\u001b[0m: \u001b[91mFailed to locate twas_fusion.ipynb.sos\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Test pipeline with test data\n",
    "## Switch back to abosolute path, otherwise there will be file not found error in step 5\n",
    "sos run susie-wgs-prior.ipynb susie \\\n",
    "  --molecular-pheno ./molecular_phenotype \\\n",
    "  --wd ./ \\\n",
    "  --genotype_list ./geno_dir\\\n",
    "  --region_list ./region_list \\\n",
    "  --region_name 1 \\\n",
    "  --data_start 5 \\\n",
    "  --window 500000 \\\n",
    "  --container /mnt/mfs/statgen/containers/twas_latest.sif \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Global parameter settings\n",
    "The section outlined the parameters that can be set in the command interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# Path to the input molecular phenotype data.\n",
    "parameter: molecular_pheno = path\n",
    "# An index text file with two columns of chromosome and the corresponding PLINK bed file.\n",
    "parameter: genotype_list = path\n",
    "# An index text file with 4 columns specifying the chr, start, end and names of regions to analyze\n",
    "parameter: region_list = path\n",
    "# Path to the work directory of the weight computation: output weights and cache will be saved to this directory.\n",
    "parameter: wd = path('./')\n",
    "# Specify the directory to save fitted weights\n",
    "parameter: weights_path = f'{wd:a}/WEIGHTS'\n",
    "# Path to list of weights\n",
    "parameter: weights_list = f'{weights_path}/{molecular_pheno:bn}.weights_list.txt'\n",
    "# Path to store the output folder\n",
    "parameter: output_path = f'{wd:a}/result'\n",
    "# Specify the column in the molecular_pheno file that contains the name of the region of interest\n",
    "parameter: region_name = int\n",
    "# Specify the column in the molecular_pheno file where the actual data start\n",
    "parameter: data_start = int\n",
    "# Specify the scanning window for the up and downstream radius to analyze around the region of interest, in units of Kb\n",
    "parameter: window = 50000\n",
    "# Specify the number of jobs per run.\n",
    "parameter: job_size = 2\n",
    "\n",
    "# Container option for software to run the analysis: docker or singularity\n",
    "parameter: container = 'gaow/twas'\n",
    "\n",
    "# Propotion of samples set into testing, set to zero if no cv are needed.\n",
    "parameter: testing_prop = 0.2\n",
    "# Number of training & testing samples used\n",
    "parameter: cv_times = 2\n",
    "\n",
    "# Minor allele frequency that are used to filter X\n",
    "parameter: MAF = 0.01\n",
    "\n",
    "\n",
    "\n",
    "# parameters for the susie pipelines.\n",
    "parameter: causal_variables_L = 10\n",
    "parameter: scaled_prior_variance = 0.1\n",
    "\n",
    "# Get regions of interest to focus on.\n",
    "regions = [x.strip().split() for x in open(region_list).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "\n",
    "geno_inventory = dict([x.strip().split() for x in open(genotype_list).readlines() if x.strip() and not x.strip().startswith('#')])\n",
    "\n",
    "import os\n",
    "def get_genotype_file(chrom, genotype_list, geno_inventory):\n",
    "    chrom = f'{chrom}'\n",
    "    if chrom.startswith('chr'):\n",
    "        chrom = chrom[3:]\n",
    "    if chrom not in geno_inventory:\n",
    "        geno_file = f'{chrom}'\n",
    "    else:\n",
    "        geno_file = geno_inventory[chrom]\n",
    "    if not os.path.isfile(geno_file):\n",
    "        # relative path\n",
    "        if not os.path.isfile(f'{genotype_list:ad}/' + geno_file):\n",
    "            raise ValueError(f\"Cannot find genotype file {geno_file}\")\n",
    "        else:\n",
    "            geno_file = f'{genotype_list:ad}/' + geno_file\n",
    "    return path(geno_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Partition of the molecular phenotype for each genes\n",
    "This step extracts the molecular phenotype for each gene and transposes them into the formats needed in the follow-up analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[hsq_1,susie_1,susie_cv_1]\n",
    "input: molecular_pheno, for_each = \"regions\"\n",
    "output: f'{wd:a}/cache/{_input:bn}.{_regions[3]}.exp',\n",
    "        f'{wd:a}/cache/{_input:bn}.{_regions[3]}.pheno'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '4h',  mem = '20G', tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout',container = container\n",
    "    # Get the line number for the region in the file\n",
    "    line_num = system(\"awk '($$[region_name]==\\\"$[_regions[3]]\\\") {print NR}' $[_input]\", intern=T)\n",
    "    if (length(line_num) == 0){\n",
    "      stop( \"Cannot find $[_regions[3]] in column $[region_name]  $[_input]\")}\n",
    "    yi <- data.table::fread(file = $[_input:r], skip = as.integer(line_num) - 1, nrows = 1)\n",
    "    samplenames_yi <- data.table::fread(file = $[_input:r], skip = 0, nrows = 1)\n",
    "    colnames(yi) <- colnames(samplenames_yi)\n",
    "    readr::write_tsv(yi, path = \"$[_output[0]]\", na = \"NA\", append = FALSE, col_names = TRUE, quote_escape = \"double\")\n",
    "    yi <- as.data.frame(yi[, $[data_start]:ncol(yi), drop = FALSE])\n",
    "    yj <- rbind(colnames(yi),colnames(yi),yi)\n",
    "    readr::write_tsv(as.data.frame(t(yj)), path = \"$[_output[1]]\", na = \"NA\", append = FALSE, col_names = TRUE, quote_escape = \"double\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Construction of Plink trio for each gene\n",
    "This step constructs the plink file for each gene based on the output of previous steps. Specifically it:\n",
    "\n",
    "1. Selects only the SNPs within the start and end position of the corresponding region (gene)\n",
    "2. Replaces the Phenotype value (last column) of the .fam based on the input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[hsq_2,susie_2,susie_cv_2]\n",
    "input: group_by = 2, group_with = 'regions'\n",
    "output: f'{_input[0]:n}.bed',\n",
    "        f'{_input[0]:n}.bim',\n",
    "        f'{_input[0]:n}.fam'\n",
    "\n",
    "# look up for genotype file\n",
    "geno_file = get_genotype_file(_regions[3],genotype_list,geno_inventory)\n",
    "\n",
    "parameter: extract_snp = f'{geno_file:an}.bim'\n",
    "parameter: exclude_snp = \"./.\"\n",
    "parameter: keep_sample = f'{_input[1]}'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '12h',  mem = '20G', tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout', container = container, volumes = [f'{geno_file:ad}:{geno_file:ad}']\n",
    "    ##### Get the locus genotypes for $[_regions[3]]\n",
    "    plink --bfile $[geno_file:an] \\\n",
    "    --pheno $[_input[1]] \\\n",
    "    --make-bed \\\n",
    "    --out $[_output[0]:n] \\\n",
    "    --chr $[_regions[0]] \\\n",
    "    --from-bp $[int(_regions[1]) - window ] \\\n",
    "    --to-bp $[int(_regions[1]) + window ] \\\n",
    "    --keep $[keep_sample] \\\n",
    "    --extract $[extract_snp]\n",
    "    --exclude $[exclude_snp]\n",
    "    --allow-no-sex || true\n",
    "    touch $[_output]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Heritability Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[hsq_3]\n",
    "input: group_by = 2, group_with = 'regions'\n",
    "output: f'{_input[0]:n}.bed',\n",
    "        f'{_input[0]:n}.bim',\n",
    "        f'{_input[0]:n}.fam'\n",
    "\n",
    "import os\n",
    "skip_if(os.path.getsize(f'{_input[0]}') == 0)\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '4h',  mem = \"20G\" , tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: expand= \"$[ ]\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout', container = container,volumes = [f'{wd:a}:{wd:a}']\n",
    "    library(\"dplyr\")\n",
    "    library(\"tibble\")\n",
    "    library(\"susieR\")\n",
    "    library(\"plink2R\")\n",
    "    library(\"readr\")\n",
    "    library(\"modelr\")\n",
    "    library(\"purrr\")\n",
    "    library(\"abind\")\n",
    "\n",
    "\n",
    "\n",
    "    # Perform i/o checks here:\n",
    "    files = c($[_input[0]],$[_input[1]],$[_input[2]])\n",
    "\n",
    "    for ( f in files ) {\n",
    "        if ( !file.exists(f) ){\n",
    "            cat( \"ERROR: \", f , \" input file does not exist\\n\" , sep='', file=stderr() )\n",
    "            cleanup()\n",
    "            q()\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if ( system( paste(\"plink\",\"--help\") , ignore.stdout=T,ignore.stderr=T ) != 0 ) {\n",
    "        cat( \"ERROR: plink could not be executed \\n\" , sep='', file=stderr() )\n",
    "        cleanup()\n",
    "        q()\n",
    "    }\n",
    "\n",
    "    if ( system( \"gcta64\" , ignore.stdout=T,ignore.stderr=T ) != 0 ){\n",
    "        cat( \"ERROR: gcta (gcta64) could not be executed \" , sep='', file=stderr() )\n",
    "        cleanup()\n",
    "        q()\n",
    "    }\n",
    "\n",
    "    # --- \n",
    "    # Set up the \"input\"\n",
    "    opt = list()\n",
    "    opt$bfile = \"$[_input[0]:n]\"\n",
    "    opt$tmp = \"$[_input[0]:n].tmp\"\n",
    "    opt$PATH_plink = \"plink\"\n",
    "    opt$PATH_gcta = \"gcta64\"\n",
    "    \n",
    "    \n",
    "    # ---\n",
    "\n",
    "    fam = read.table(paste(opt$bfile,\".fam\",sep=''),as.is=T)\n",
    "\n",
    "    # Make/fetch the phenotype file\n",
    "    \n",
    "        pheno.file = paste(opt$tmp,\".pheno\",sep='')\n",
    "        pheno = fam[,c(1,2,6)]\n",
    "        write.table(pheno,quote=F,row.names=F,col.names=F,file=pheno.file)\n",
    "   \n",
    "    geno.file = opt$tmp\n",
    "    # recode to the intersection of samples and new phenotype\n",
    "    arg = paste( opt$PATH_plink ,\" --allow-no-sex --bfile \",opt$bfile,\" --pheno \",pheno.file,\" --keep \",pheno.file,\" --make-bed --out \",geno.file,sep='')\n",
    "    system(arg , ignore.stdout=SYS_PRINT,ignore.stderr=SYS_PRINT)\n",
    "\n",
    "    # --- HERITABILITY ANALYSIS\n",
    "    \n",
    "    # 1. generate GRM\n",
    "    arg = paste( opt$PATH_plink,\" --allow-no-sex --bfile \",opt$tmp,\" --make-grm-bin --out \",opt$tmp,sep='')\n",
    "    system(arg , ignore.stdout=SYS_PRINT,ignore.stderr=SYS_PRINT)\n",
    "\n",
    "    # 2. estimate heritability\n",
    "    if ( !is.na(opt$covar) ) {\n",
    "    arg = paste( opt$PATH_gcta ,\" --grm \",opt$tmp,\" --pheno \",raw.pheno.file,\" --qcovar \",opt$covar,\" --out \",opt$tmp,\" --reml --reml-no-constrain --reml-lrt 1\",sep='')\n",
    "    } else {\n",
    "    arg = paste( opt$PATH_gcta ,\" --grm \",opt$tmp,\" --pheno \",pheno.file,\" --out \",opt$tmp,\" --reml --reml-no-constrain --reml-lrt 1\",sep='')\n",
    "    }\n",
    "    system(arg , ignore.stdout=SYS_PRINT,ignore.stderr=SYS_PRINT)\n",
    "\n",
    "    # 3. evaluate LRT and V(G)/Vp\n",
    "    if ( !file.exists( paste(opt$tmp,\".hsq\",sep='') ) ) {\n",
    "        cat(opt$tmp,\"does not exist, likely GCTA could not converge, skipping gene\\n\",file=stderr())\n",
    "        cleanup()\n",
    "        q()\n",
    "    }\n",
    "\n",
    "    hsq.file = read.table(file=paste(opt$tmp,\".hsq\",sep=''),as.is=T,fill=T)\n",
    "    hsq = as.numeric(unlist(hsq.file[hsq.file[,1] == \"V(G)/Vp\",2:3]))\n",
    "    hsq.pv = as.numeric(unlist(hsq.file[hsq.file[,1] == \"Pval\",2]))\n",
    "\n",
    "    if ( opt$verbose >= 1 ) cat(\"Heritability (se):\",hsq,\"LRT P-value:\",hsq.pv,'\\n')\n",
    "    if ( opt$save_hsq ) cat( opt$out , hsq , hsq.pv , '\\n' , file=paste(opt$out,\".hsq\",sep='') )\n",
    "\n",
    "    # 4. stop if insufficient\n",
    "    if ( hsq[1] < 0 || hsq.pv > opt$hsq_p ) {\n",
    "        cat(opt$tmp,\" : heritability \",hsq[1],\"; LRT P-value \",hsq.pv,\" : skipping gene\\n\",sep='',file=stderr())\n",
    "        cleanup()\n",
    "        q()\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Conducting univariate test for all the genes and save the sumstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "#Susie test\n",
    "[susie_3,susie_cv_3]\n",
    "input:  group_by = 3, group_with = 'regions'\n",
    "output: f'{wd:a}/susie/{_input[0]:bn}.susie.model.RData',\n",
    "        f'{wd:a}/susie/{_input[0]:bn}.uni_weight.rds'\n",
    "\n",
    "import os\n",
    "skip_if(os.path.getsize(f'{_input[0]}') == 0)\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '4h',  mem = \"60G\" , tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: expand= \"$[ ]\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout', container = container,volumes = [f'{wd:a}:{wd:a}']\n",
    "    library(\"dplyr\")\n",
    "    library(\"tibble\")\n",
    "    library(\"susieR\")\n",
    "    library(\"plink2R\")\n",
    "    library(\"readr\")\n",
    "    library(\"modelr\")\n",
    "    library(\"purrr\")\n",
    "    library(\"abind\")\n",
    "\n",
    "    # Define functions\n",
    "    ###Functions to compute MAF and missing genotype rate\n",
    "    compute_maf <- function(geno){\n",
    "      f <- mean(geno,na.rm = TRUE)/2\n",
    "      return(min(f, 1-f))\n",
    "    }\n",
    "    \n",
    "    compute_missing <- function(geno){\n",
    "      miss <- sum(is.na(geno))/length(geno)\n",
    "      return(miss)\n",
    "    }\n",
    "    \n",
    "    mean_impute <- function(geno){\n",
    "      f <- apply(geno, 2, function(x) mean(x,na.rm = TRUE))\n",
    "      for (i in 1:length(f)) geno[,i][which(is.na(geno[,i]))] <- f[i]\n",
    "      return(geno)\n",
    "    }\n",
    "    \n",
    "    is_zero_variance <- function(x) {\n",
    "      if (length(unique(x%>%na.omit()))==1) return(T)\n",
    "      else return(F)\n",
    "    }\n",
    "    ### Filter X matrix\n",
    "    filter_X <- function(X, missing_rate_thresh, maf_thresh) {\n",
    "      rm_col <- which(apply(X, 2, compute_missing) > missing_rate_thresh)\n",
    "      if (length(rm_col)) X <- X[, -rm_col]\n",
    "      rm_col <- which(apply(X, 2, compute_maf) < maf_thresh)\n",
    "      if (length(rm_col)) X <- X[, -rm_col]\n",
    "      rm_col <- which(apply(X, 2, is_zero_variance))\n",
    "      if (length(rm_col)) X <- X[, -rm_col]\n",
    "      return(mean_impute(X))}\n",
    "      \n",
    "    ###Function to impute the missing X with means and then scale and center X\n",
    "      impute_and_transform = function(genos,impute = TRUE){\n",
    "      tmp = genos\n",
    "      if(impute == TRUE){\n",
    "      for(i in 1:ncol(tmp)){\n",
    "        tmp[,i]=coalesce(tmp[,i],mean(tmp[,i]%>%na.omit()))%>%scale()}\n",
    "        return(tmp)\n",
    "      } else {\n",
    "    for(i in 1:ncol(tmp)){\n",
    "        tmp[,i]=tmp[,i]%>%scale()}\n",
    "        return(tmp)}}\n",
    "        \n",
    "    ###Function to impute the weight and standard errors\n",
    "    \n",
    "    mm_regression = function(X, Y, Z=NULL,center=TRUE,scale=TRUE) {\n",
    "    ## HS: Make sure X and Y is matrixs as well otherwise the ncol(Y) give error\n",
    "    X = as.matrix(X)\n",
    "    Y = as.matrix(Y)\n",
    "    if (!is.null(Z)) {\n",
    "    Z = as.matrix(Z)\n",
    "    }\n",
    "    if(any(is.na(Y))){\n",
    "    reg = lapply(seq_len(ncol(Y)), function (i) simplify2array(susieR:::univariate_regression(X, Y[,i], Z, center, scale)))\n",
    "    reg = do.call(abind, c(reg, list(along=0)))\n",
    "    # return array: out[1,,] is betahat, out[2,,] is shat\n",
    "    out = aperm(reg, c(3,2,1))\n",
    "    #HS Force dimension for the matrix slice.\n",
    "    out = list(bhat = as.matrix(out[1,,]), sbhat=as.matrix(out[2,,]))\n",
    "    }else{\n",
    "    out = univariate_regression(X, Y, Z, center = F, scale = F)\n",
    "    #HS Original out dont has betahat instead of bhat, fixed now.\n",
    "    out$bhat = as.matrix(out$betahat)\n",
    "    out$sbhat = as.matrix(out$sebetahat)\n",
    "    }\n",
    "    if (!is.null(colnames(X))) {\n",
    "    rownames(out$bhat) = colnames(X)\n",
    "    rownames(out$sbhat) = colnames(X)\n",
    "    }\n",
    "    if (!is.null(colnames(Y))) {\n",
    "    colnames(out$bhat) = colnames(Y)\n",
    "    colnames(out$sbhat) = colnames(Y)\n",
    "    }\n",
    "    # `out` is a list of bhat and sbhat\n",
    "    return(out)\n",
    "    }\n",
    "\n",
    "    # Load data and transform\n",
    "    genos = read_plink(\"$[_input[0]:n]\")\n",
    "  \n",
    "    # Filter X by 0.1 NA and 0.01 MAF, and then transfrom X\n",
    "    \n",
    "    X_ftr = filter_X(genos$bed,0.1,$[MAF])\n",
    "    X = impute_and_transform(X_ftr,impute = FALSE)\n",
    "    \n",
    "    Y = genos$fam%>%as_tibble()%>%mutate(name = paste(V1,\":\",V2,sep = \"\"))\n",
    "    \n",
    "    # Make sure X and Y have the same order\n",
    "    Y = Y%>%arrange(match(name,rownames(X)))%>%select(V6)\n",
    "    \n",
    "    \n",
    "    # Center and scale Y \n",
    "    \n",
    "    Y = impute_and_transform(Y, impute = FALSE )\n",
    "    Y = Y$V6\n",
    "    \n",
    "    # Susie with full samples\n",
    "    full_model = susie(X, Y,\n",
    "                  L = $[causal_variables_L],\n",
    "                  estimate_residual_variance = TRUE, \n",
    "                  estimate_prior_variance = FALSE,\n",
    "                  scaled_prior_variance = $[scaled_prior_variance])\n",
    "                  \n",
    "\n",
    "    # Get sumstat from the univariate regression\n",
    "    \n",
    "    uni = mm_regression(X,Y,center=FALSE,scale=FALSE)\n",
    "    \n",
    "    # Save the sumstat objects\n",
    "    \n",
    "    uni%>%saveRDS(\"$[_output[1]]\")\n",
    "    \n",
    "    # Save the model for future use\n",
    "    full_model$X = X\n",
    "    full_model$Y = Y\n",
    "    save(full_model, file=\"$[_output[0]]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# CV with univariate susie\n",
    "[susie_cv_4]\n",
    "input: group_by = 2, group_with = 'regions'\n",
    "output:  f'{wd:a}/susie/{_input[0]:bn}.cv.RData',\n",
    "         f'{wd:a}/susie/{_input[0]:bn}.cv_diag.RData'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '12h',  mem = '60G', tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: expand= \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout',container = container\n",
    "    library(\"dplyr\")\n",
    "    library(\"tibble\")\n",
    "    library(\"readr\")\n",
    "    library(\"purrr\")\n",
    "    library(\"modelr\")\n",
    "    library(\"susieR\")\n",
    "    \n",
    "    # Define functions\n",
    "   \n",
    "    ## Compute rmse function\n",
    "    compute_rmse = function(raw,fitted){\n",
    "    rmse = rep(0,ncol(raw))\n",
    "    for (i in 1:ncol(raw)){\n",
    "      rmse[i] = ((fitted - raw)[,i])^2%>%mean(na.rm = TRUE)%>%sqrt() \n",
    "      }\n",
    "    return(rmse)\n",
    "    }\n",
    "    \n",
    "    ## Compute r2 function\n",
    "    compute_r2 = function(raw,fitted){\n",
    "      r2 = rep(0,ncol(raw))\n",
    "      for (j in 1:ncol(raw)){\n",
    "       r2[j] = summary(lm( as.matrix(fitted[,j]) ~ as.matrix(raw[,j]) ))$adj.r.sq\n",
    "      }\n",
    "      return(r2)\n",
    "    }\n",
    "    \n",
    "    ## Compute r2 raw\n",
    "    \n",
    "    compute_r2_raw = function(raw,fitted){\n",
    "      r2 = rep(0,ncol(raw))\n",
    "      for (j in 1:ncol(raw)){\n",
    "        r2[j] =  cor(as.matrix(fitted[,j])[which(!is.na(raw[,j]))],raw[,j]%>%na.omit())^2\n",
    "      }\n",
    "      return(r2)\n",
    "    }\n",
    "    \n",
    "    ## Get P.value\n",
    "    compute_pval = function(raw,fitted){\n",
    "      pval = rep(0,ncol(raw))\n",
    "      for (k in 1:ncol(raw)){\n",
    "        pval[k] = summary(lm( fitted[,k]%>%as.matrix ~ raw[,k]%>%as.matrix ))$coef[2,4]\n",
    "      }\n",
    "      return(pval)\n",
    "    }\n",
    "    \n",
    "    \n",
    "\n",
    "    ###Functions to compute MAF and missing genotype rate\n",
    "    compute_maf <- function(geno){\n",
    "      f <- mean(geno,na.rm = TRUE)/2\n",
    "      return(min(f, 1-f))\n",
    "    }\n",
    "    \n",
    "    compute_missing <- function(geno){\n",
    "      miss <- sum(is.na(geno))/length(geno)\n",
    "      return(miss)\n",
    "    }\n",
    "    \n",
    "    mean_impute <- function(geno){\n",
    "      f <- apply(geno, 2, function(x) mean(x,na.rm = TRUE))\n",
    "      for (i in 1:length(f)) geno[,i][which(is.na(geno[,i]))] <- f[i]\n",
    "      return(geno)\n",
    "    }\n",
    "    \n",
    "    is_zero_variance <- function(x) {\n",
    "      if (length(unique(x))==1) return(T)\n",
    "      else return(F)\n",
    "    }\n",
    "    ### Filter X matrix\n",
    "    filter_X <- function(X, missing_rate_thresh, maf_thresh) {\n",
    "      rm_col <- which(apply(X, 2, compute_missing) > missing_rate_thresh)\n",
    "      if (length(rm_col)) X <- X[, -rm_col]\n",
    "      rm_col <- which(apply(X, 2, compute_maf) < maf_thresh)\n",
    "      if (length(rm_col)) X <- X[, -rm_col]\n",
    "      rm_col <- which(apply(X, 2, is_zero_variance))\n",
    "      if (length(rm_col)) X <- X[, -rm_col]\n",
    "      return(mean_impute(X))\n",
    "    }\n",
    "    \n",
    "    ### Produce CV dataset\n",
    "    cv_data_gen = function(X,Y,times,test_prop){\n",
    "    # Merged the X and Y for producing testing and training set for modelr cv\n",
    "    cv_df_raw = cbind(X,Y)%>%as_tibble() \n",
    "    cv_df = crossv_mc(cv_df_raw, times ,test = test_prop)%>%mutate(\n",
    "      train_X = map(train,~as_tibble(.x)[1:ncol(X)]%>%as.matrix),\n",
    "      train_Y = map(train,~as_tibble(.x)[(ncol(X)+1):(ncol(X)+ncol(Y))]%>%as.matrix),\n",
    "      test_X = map(test,~as_tibble(.x)[1:ncol(X)]%>%as.matrix),\n",
    "      test_Y = map(test,~as_tibble(.x)[(ncol(X)+1):(ncol(X)+ncol(Y))]%>%as_tibble)\n",
    "    )  \n",
    "    \n",
    "    # Filter Train X with maf and missing, filter test X with the same col as Train X\n",
    "    cv_df = cv_df%>%mutate(\n",
    "    train_X = map(train_X,~filter_X(.x,0.1,$[MAF])),\n",
    "    test_X = map2(test_X,train_X,~.x%>%as_tibble()%>%select(colnames(.y))%>%as.matrix())\n",
    "    )\n",
    "    return(cv_df)\n",
    "    }\n",
    "    \n",
    "    # Load Data\n",
    "    full_model = attach('$[_input[0]]')$full_model\n",
    "    X = full_model$X\n",
    "    Y = full_model$Y%>%as.tibble()\n",
    "\n",
    "    # Create cv dataset\n",
    "        \n",
    "    cv_df = cv_data_gen(X,Y,$[cv_times],$[testing_prop])\n",
    "\n",
    "    # Actual cv\n",
    "    \n",
    "    cv_df = cv_df%>%mutate(\n",
    "    \n",
    "   \n",
    "    ## Do susie\n",
    "    \n",
    "      susie = pmap(list(train_X,train_Y),function(first,second)(\n",
    "        \n",
    "        susie(first, second,\n",
    "        L = $[causal_variables_L],\n",
    "        estimate_residual_variance = TRUE, \n",
    "        estimate_prior_variance = FALSE,\n",
    "        scaled_prior_variance = $[scaled_prior_variance])\n",
    "        )))\n",
    "    \n",
    "    # Extract data \n",
    "    \n",
    "    cv_df = cv_df%>%mutate(\n",
    "      weight = map(susie,~\n",
    "      (coef(.x)[2:length(coef(.x))])\n",
    "      ),\n",
    "      test_fitted = map2(susie,test_X,~predict(.x,.y)%>%as_tibble),\n",
    "      rmse = map2(test_Y,test_fitted,~compute_rmse(.x,.y)),\n",
    "      r2 = map2(test_Y,test_fitted,~compute_r2(.x,.y)),\n",
    "      r2_raw = map2(test_Y,test_fitted,~compute_r2_raw(.x,.y)),\n",
    "      pval = map2(test_Y,test_fitted,~compute_pval(.x,.y))\n",
    "    )\n",
    "    \n",
    "    # Calculate metrics\n",
    "    \n",
    "    mean_rmse = cv_df%>%pull(rmse)%>%as.data.frame()%>%t()%>%as_tibble()%>%colMeans()\n",
    "    mean_r2 = cv_df%>%pull(r2)%>%as.data.frame()%>%t()%>%as_tibble()%>%colMeans()\n",
    "    mean_r2_raw = cv_df%>%pull(r2_raw)%>%as.data.frame()%>%t()%>%as_tibble()%>%colMeans()\n",
    "    mean_pval = cv_df%>%pull(pval)%>%as.data.frame()%>%t()%>%as_tibble()%>%colMeans()\n",
    "\n",
    "  \n",
    "    # Save metrics\n",
    "    full_model$rmse = mean_rmse\n",
    "    full_model$r2 = mean_r2 \n",
    "    full_model$r2_raw = mean_r2_raw    \n",
    "    full_model$pval = mean_pval    \n",
    "    fitted1 = full_model\n",
    "    # Save the CV data\n",
    "    save(cv_df,file = \"$[_output[1]]\")\n",
    "    \n",
    "    #Output\n",
    "    save(fitted1,file = \"$[_output[0]]\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Save output\n",
    "This step create the all_hsq.txt file to summarize the susie result and create a R object to host all the susieR models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "#Saved selected susie object into one RData\n",
    "[condense]\n",
    "input: group_by = \"all\"\n",
    "output:f'{wd:a}/susie/all_hsq.txt',\n",
    "       f'{wd:a}/susie.RData'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '12h',  mem = '20G', tags = f'{step_name}_{_output[0]:bn}'\n",
    "\n",
    "R: expand= \"$[ ]\", stderr = f'{_output[1]}.stderr', stdout = f'{_output[1]}.stdout',container = container\n",
    "    library(\"dplyr\")\n",
    "    library(\"tibble\")\n",
    "    library(\"readr\")\n",
    "    library(\"purrr\")\n",
    "    # Load a template\n",
    "    region = read_delim(\"$[_output[0]]\",delim =\"\\t\")%>%select(path = file, ID = region )\n",
    "    # get the path\n",
    "    dir = \"$[_input[0]:d]/\"\n",
    "    pre = \"$[_input[0]:bnnnnn]\"\n",
    "    sur = \".susie.model.RData\"\n",
    "    region = region%>%mutate(path = map(ID, ~paste(collapse = \"\", c(dir,pre,\".\",.x,sur))))\n",
    "    # Load the data\n",
    "    output = region%>%mutate(env = map(path,~attach(.x)),\n",
    "                             model = map(env, ~.x$fitted1))\n",
    "    # Save the combined output\n",
    "    save(output,file = \"$[_output[1]]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "#Create all_hsq for susie and saved all the susie object into one RData\n",
    "[susie_4]\n",
    "input: group_by = \"all\"\n",
    "output:f'{wd:a}/susie/all_hsq.txt',\n",
    "       f'{wd:a}/susie.RData'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '12h',  mem = '20G', tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: expand= \"$[ ]\"\n",
    "  head -1 $[_input[0]] > $[_output[0]]\n",
    "  cat $[wd:a]/susie/*.hsq | grep -v hsq_full_sample | uniq >> $[_output[0]]\n",
    "\n",
    "R: expand= \"$[ ]\", stderr = f'{_output[1]}.stderr', stdout = f'{_output[1]}.stdout',container = container\n",
    "    library(\"dplyr\")\n",
    "    library(\"tibble\")\n",
    "    library(\"readr\")\n",
    "    library(\"purrr\")\n",
    "    # Load a template\n",
    "    region = read_delim(\"$[_output[0]]\",delim =\"\\t\")%>%select(path = file, ID = region )\n",
    "    # get the path\n",
    "    dir = \"$[_input[0]:d]/\"\n",
    "    pre = \"$[_input[0]:bnnnnn]\"\n",
    "    sur = \".susie.model.RData\"\n",
    "    region = region%>%mutate(path = map(ID, ~paste(collapse = \"\", c(dir,pre,\".\",.x,sur))))\n",
    "    # Load the data\n",
    "    output = region%>%mutate(env = map(path,~attach(.x)),\n",
    "                             model = map(env, ~.x$fitted1))\n",
    "    # Save the combined output\n",
    "    save(output,file = \"$[_output[1]]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "#Create all_hsq for susie and saved all the susie object into one RData\n",
    "[susie_cv_5]\n",
    "input: group_by = \"all\"\n",
    "output:f'{wd:a}/susie/all_hsq.txt',\n",
    "       f'{wd:a}/susie_cv.RData'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '12h',  mem = '20G', tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: expand= \"$[ ]\"\n",
    "\n",
    "  head -1 $[_input[0]:nnn].hsq > $[_output[0]]\n",
    "  cat $[wd:a]/susie/*.hsq | grep -v hsq_full_sample | uniq >> $[_output[0]]\n",
    "\n",
    "R: expand= \"$[ ]\", stderr = f'{_output[1]}.stderr', stdout = f'{_output[1]}.stdout',container = container\n",
    "    library(\"dplyr\")\n",
    "    library(\"tibble\")\n",
    "    library(\"readr\")\n",
    "    library(\"purrr\")\n",
    "    # Load a template\n",
    "    region = read_delim(\"$[_output[0]]\",delim =\"\\t\")%>%select(path = file, ID = region )\n",
    "    # get the path\n",
    "    dir = \"$[_input[0]:d]/\"\n",
    "    pre = \"$[_input[0]:bnnnnn]\"\n",
    "    sur = \".susie.model.cv.RData\"\n",
    "    region = region%>%mutate(path = map(ID, ~paste(collapse = \"\", c(dir,pre,\".\",.x,sur))))\n",
    "    # Load the data\n",
    "    output = region%>%mutate(env = map(path,~attach(.x)),\n",
    "                             model = map(env, ~.x$fitted1))\n",
    "    # Save the combined output\n",
    "    save(output,file = \"$[_output[1]]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "calysto_bash",
     "Bash",
     "#E6EEFF",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.20.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
